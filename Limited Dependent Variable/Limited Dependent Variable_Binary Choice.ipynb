{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Choice \n",
    "## Basic Framework\n",
    "It is always easy to start from the micro-foundation of the model:\n",
    "<p> whether you choose 1 or 0 is based on the following mechanism: if \n",
    "    $$\n",
    "    y^*_i={x'}_i\\beta +\\epsilon_i>0\n",
    "    $$\n",
    "    then choose $y_i=1$. otherwise choose $y_i=0$. $\\epsilon_i$ follows $N(0, \\sigma^2)$\n",
    "    </p>\n",
    "Therefore we have the formula\n",
    "$$\n",
    "pr(y_i=1|x_i)= pr(y^*_i>0|x_i)=pr({x'}_i\\beta +\\epsilon_i>0|x_i)=pr(\\epsilon_i>-{x'}_i\\beta|x_i)\n",
    "$$\n",
    "$$\n",
    "= pr(\\frac{\\epsilon_i}{\\sigma}>-\\frac{{x'}_i\\beta}{\\sigma}|x_i)= \\Phi(\\frac{{x'}_i\\beta}{\\sigma}) \\tag{1}\n",
    "$$\n",
    "in which the last equation applies the fact that $\\epsilon_i$ is symmetric distributed.The likelihood function for individual $i$ is therefore \n",
    "$$\n",
    "{\\left(\\Phi(\\frac{{x'}_i\\beta}{\\sigma})\\right)}^{d_i}{\\left(1-\\Phi(\\frac{{x'}_i\\beta}{\\sigma})\\right)}^{1-d_i}\n",
    "$$\n",
    "We can then estimate the $\\frac{\\beta}{\\sigma}$ using MLE (Notice that apparently we are not able to indentify $\\beta$ and $\\sigma$ separately.)\\\n",
    "<p>This framework is obvious over simplified. In fact there are some issues here:</p>\n",
    "<p>1. What if $\\epsilon_i$'s have different $\\sigma_i$? $\\rightarrow $ Probit model with heteroskasticity.\n",
    "<p>2. What if $\\epsilon_i$'s distribution is not symmetric? $\\rightarrow $ Complementary log-log model\n",
    "<p>3. What if $x$'s is endogeneous? \n",
    "<p>4. What if there are two dicrete choices made simultaneously? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probit model with Heteroskasticity\n",
    "Now we assume $\\epsilon_i$ follows $N(0, \\sigma^2_i)$. Furthermore, following the typical practice of modeling the heteroskasticity, we assume $\\sigma^2_i = e^{z'_i \\gamma}$. plug this into (1) we have \n",
    "$$\n",
    "pr(y_i=1|x_i)= \\Phi(\\frac{{x'}_i\\beta}{\\sigma_i})= \\Phi (\\frac{{x'}_i\\beta}{\\sqrt{e^{z'_i \\gamma}} })\n",
    "$$\n",
    "There the likehood function for individual $i$ is \n",
    "$$\n",
    "{\\left(\\Phi(\\frac{{x'}_i\\beta}{\\sqrt{e^{z'_i \\gamma}}})\\right)}^{d_i}{\\left(1-\\Phi(\\frac{{x'}_i\\beta}{\\sqrt{e^{z'_i \\gamma}}})\\right)}^{1-d_i}\n",
    "$$\n",
    "Now we can estimate the $\\gamma$ and $\\beta$. After estimating we get the esimation of $\\gamma$, we can test the null hypothesis $\\gamma =0$ (how?). If we reject this null hypothesis, then we think that we should keep the heteroskasticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Choice Model with Asymmetrical Extreme Value Distribution \n",
    "### Basic motivation: unbalanced data\n",
    "A close examination of the the mle gives \n",
    "$$\n",
    "L(\\beta)= \\sum_{i=1}^{N}{d_i\\log{\\left(\\Phi(\\frac{{x'}_i\\beta}{\\sigma})\\right)} + (1-d_i)\\log{\\left(1-\\Phi(\\frac{{x'}_i\\beta}{\\sigma})\\right) } }\n",
    "$$\n",
    "The idea of mle here is to find a threshold (which is a $-\\beta x$, i.e., a linear combination of explanatory variables ) (when $\\epsilon$ is above this threshold, choose $y=1$, otherwise choose $y=0$) to maximize the 'sum' of the possibility of each individual.\n",
    "<p>fix the distribution of $\\epsilon$. when you raise the threshold, it(a) increases the possibility of choosing $y=0$(i.e., increase the likelihood of those samples with $y=0$) but (b)reduces the probabiliy of choosing $y=1$ (i.e., reduce the likelihood of those samples with $y=1$),since $\\epsilon$ have to be even larger to get over the threshold. Therefore, to maximize the over-all likehood, the $\\beta$ should not be too large due to (b)</p>\n",
    "<p> Now, however, consider a situation where most of the individuals are 0 and only a few are 1 (due to some exogenous reasons). What happens to the mle? The negative effect of(b) on overall likelihood now becomes pretty small, since there are only a few individuals with $y=1$. Therefore,to maximize the overal llikelihood, the estimated threshold could be quite high, higher than the ones under cases where there are more $y=1$ in the sample.  </p>\n",
    "<p>The above reasoning implies that too few $y=1$ may well lead to a systematic higher estimation of the threshold.(i.e., higher than what it really should be.) Chenqiang (2014) provides another intuitive explanation. </p>\n",
    "\n",
    "### Correction of such bias\n",
    "#### put more weight on the minor\n",
    "This a natural way to deal with this. By adding more weight to the minor sample.. (but how?)\n",
    "#### set an alternative distribution of $\\epsilon$\n",
    "instead of the standard case of binary choice model in which the error term follows logit distribution or normal distribution (both are symmetric), here we assume\n",
    "$$\n",
    "pr(y_i=1 |x_i)=pr(\\epsilon_i>-\\beta x_i |x_i)= 1-e^{-e^{\\beta x_i}} \n",
    "$$\n",
    "a property of this function is that, when $\\beta x_i$ increases(declines), $pr(y_i=1 |x_i)$ goes to 1 (0), but the speed of going to 1 is higher than that in the normal or logit distribution. <b>This means, for the given sample set, if you increase the threshold $-\\beta x$ by a little amount, (i.e., reduce $\\beta x_i$),  the marginal deline of $pr(y_i=1 |x_i)$ will be 'large'. the marginal decline of the likelihood of those sample with $y_i=1$ would be 'large'.</b> faced with this, the optimal level threshold would be small than that under the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Choice with Endogenous variables\n",
    "If we are familiar with the textbook the specification of the endogeneity problem, we can easily write down the following framework\n",
    "$$\n",
    "y^*_1= y'_2\\beta+ u,\\quad y^*_2 = z'\\gamma + v\n",
    "$$\n",
    "$y_1=1$ if $y^*_1 >0$, and $y_1=0$ if $y^*_1 <0$.Assume that $u$ and $v$ are correlated unobservable terms (joint normal distribution with $\\sigma_u$,$\\sigma_v$,$\\rho$), and $\\sigma_u = 1$. Also assume that $cov(z,u)=0$,$cov(z,v)=0$. Of course,if $\\rho \\ne 0$, we can see here that $y'_2$ is an endogeneous variable, since $cov(y_2, u)=cov( z'\\gamma + v, u)=cov(v,u)\\ne 0$\n",
    "\n",
    "### Method 1 : MLE\n",
    "Intuitive we can estimate the $\\beta$ using mle, incorporating $y_1$ and $y_2$.\n",
    "$$\n",
    "pr(y_1 =1, y_2 = y )= pr (y_1 =1 | y_2 = y)pr( y_2 = y )\n",
    "$$\n",
    "$$\n",
    "=pr (u>-y'_2\\beta | y_2 = y)f( y_2 = y )\n",
    "$$\n",
    "$$\n",
    "=pr (u>-y'_2\\beta | v= y-z'\\gamma  )f_v( y-z'\\gamma )\n",
    "$$\n",
    "It is easy to calculate this two terms given the joint distribution of $u$ and $v$.\\\n",
    "\n",
    "### Method 2: Control Function Approach: two step\n",
    "See the note on Contral Function Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Binary Choices\n",
    "Sometimes, people make two choices. Suppose you are a patient. You make choice on whether to go to see the doctor. You also make choice on whether to get treatment at the hospital. Apparently these two choices are related: if you are willing to get treatment at the hospital, then you may also want to go to see the doctor. Now see the following framework, where an invidual makes choice on two variables, $y_1$ and $y_2$\n",
    "$$\n",
    "y^*_1 = x'_1\\beta_1 +\\epsilon_1, \\quad y^*_2 = x'_2\\beta_2 +\\epsilon_2\n",
    "$$\n",
    "and assume $y_1=1$ if $y^*_1 >0$, and $y_1=0$ if $y^*_1 <0$. The same for 2. \n",
    "$$\n",
    "\\left[\\begin{array}{c}\n",
    "            \\epsilon_1 \\\\\n",
    "            \\epsilon_2 \\\\\n",
    "        \\end{array}\\right] follows \\quad   \n",
    "        N\n",
    "        \\left[\\begin{array}{cc}\n",
    "            \\left[\\begin{array}{c}\n",
    "            0 \\\\\n",
    "            0 \\\\\n",
    "        \\end{array}\\right] ,\n",
    "            \\left[\\begin{array}{cc}\n",
    "            1,\\rho \\\\\n",
    "            \\rho,1 \\\\\n",
    "        \\end{array}\\right]  \\\\   \n",
    "        \\end{array}\\right] \n",
    "$$\n",
    "It is easy to see that when$\\rho=0$, we can separately estimate the two models. otherwise, it is more efficient (?why?) to estimate two models jointly\n",
    "$$\n",
    "pr(y_1 = 1, y_2 = 1)= pr(  \\epsilon_1>-x'_1\\beta_1, \\epsilon_2>-x'_2\\beta_2)= \n",
    "$$\n",
    "$$\n",
    "pr(  \\epsilon_1<x'_1\\beta_1, \\epsilon_2<x'_2\\beta_2)= \\Phi(x'_1\\beta_1,x'_2\\beta_2,\\rho)\n",
    "$$\n",
    "denote this as $p_{11}$. It is easy to write down $p_{10}$,$p_{01}$,$p_{00}$ and we can immediately write down the likelihood for each individual.we can also test hypothesis $\\rho =0$ (how?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
